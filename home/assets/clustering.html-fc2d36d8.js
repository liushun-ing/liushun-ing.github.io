import{_ as s,o as e,c as n,a}from"./app-0bc2a4b0.js";const t="/home/assets/remotewrite-a96b3acf.png",r="/home/assets/remoteread-57c2aa8b.png",o="/home/assets/fanderate-9aaca618.png",p="/home/assets/PARTITION-adb64d9a.png",i="/home/assets/baseha-50714e0b.png",l="/home/assets/baseharemotes-572259af.png",u="/home/assets/haremotefunderatre-ca45b7bd.png",c="/home/assets/alertsingle-5e985925.png",d="/home/assets/alertfeature-d2256489.png",m="/home/assets/multialert-b4788fd9.png",h="/home/assets/gossip-da4d90b8.png",v="/home/assets/gossipprotocol-2f4295f3.png",k="/home/assets/pipeline-e3afbb07.png",g="/home/assets/twogossip-86838e5f.png",b={},P=a(`<h1 id="集群与高可用" tabindex="-1"><a class="header-anchor" href="#集群与高可用" aria-hidden="true">#</a> 集群与高可用</h1><p>这里就不自己实验了，就看看好了</p><p>Prometheus内置了一个基于本地存储的时间序列数据库。在Prometheus设计上，使用本地存储可以降低Prometheus部署和管理的复杂度同时减少高可用（HA）带来的复杂性。 在默认情况下，用户只需要部署多套Prometheus，采集相同的Targets即可实现基本的HA。同时由于Promethus高效的数据处理能力，单个Prometheus Server基本上能够应对大部分用户监控规模的需求。</p><p>当然本地存储也带来了一些不好的地方，首先就是数据持久化的问题，特别是在像Kubernetes这样的动态集群环境下，如果Promthues的实例被重新调度，那所有历史监控数据都会丢失。 其次本地存储也意味着Prometheus不适合保存大量历史数据(一般Prometheus推荐只保留几周或者几个月的数据)。最后本地存储也导致Prometheus无法进行弹性扩展。为了适应这方面的需求，Prometheus提供了remote_write和remote_read的特性，支持将数据存储到远端和从远端读取数据。通过将监控与数据分离，Prometheus能够更好地进行弹性扩展。</p><p>除了本地存储方面的问题，由于Prometheus基于Pull模型，当有大量的Target需要采样本时，单一Prometheus实例在数据抓取时可能会出现一些性能问题，联邦集群的特性可以让Prometheus将样本采集任务划分到不同的Prometheus实例中，并且通过一个统一的中心节点进行聚合，从而可以使Prometheuse可以根据规模进行扩展。</p><p>当然除了Prometheus自身的高可用，Alertmanager作为Promthues体系中的告警处理中心，也有Alertmanager的高可用部署。</p><h2 id="本地存储" tabindex="-1"><a class="header-anchor" href="#本地存储" aria-hidden="true">#</a> 本地存储</h2><p>Prometheus 2.x 采用自定义的存储格式将样本数据保存在本地磁盘当中。如下所示，按照两个小时为一个时间窗口，将两小时内产生的数据存储在一个块(Block)中，<strong>每一个块中包含该时间窗口内的所有样本数据(chunks)，元数据文件(meta.json)以及索引文件(index)。</strong></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>t0            t1             t2             now
 ┌───────────┐  ┌───────────┐  ┌───────────┐
 │           │  │           │  │           │                 ┌────────────┐
 │           │  │           │  │  mutable  │ &lt;─── write ──── ┤ Prometheus │
 │           │  │           │  │           │                 └────────────┘
 └───────────┘  └───────────┘  └───────────┘                        ^
       └──────────────┴───────┬──────┘                              │
                              │                                   query
                              │                                     │
                            merge ──────────────────────────────────┘
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>当前时间窗口内正在收集的样本数据，Prometheus则会直接将数据保存在<strong>内存</strong>当中。为了确保此期间如果Prometheus发生崩溃或者重启时能够恢复数据，Prometheus启动时<strong>会从写入日志(WAL)进行重播</strong>，从而恢复数据。此期间如果通过API删除时间序列，<strong>删除记录也会保存在单独的逻辑文件当中(tombstone)</strong>。</p><p>在文件系统中这些块保存在单独的目录当中，Prometheus保存块数据的目录结构如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>./data 
   |- 01BKGV7JBM69T2G1BGBGM6KB12 # 块
      |- meta.json  # 元数据
      |- wal        # 写入日志
        |- 000002
        |- 000001
   |- 01BKGTZQ1SYQJTR4PB43C8PD98  # 块
      |- meta.json  #元数据
      |- index   # 索引文件
      |- chunks  # 样本数据
        |- 000001
      |- tombstones # 逻辑数据
   |- 01BKGTZQ1HHWHV8FBJXW1Y3W0K
      |- meta.json
      |- wal
        |-000001
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过时间窗口的形式保存所有的样本数据，可以明显提高Prometheus的查询效率，当查询一段时间范围内的所有样本数据时，只需要简单的从落在该范围内的块中查询数据即可。</p><p>同时该存储方式可以简化历史数据的删除逻辑。只要一个块的时间范围落在了配置的保留范围之外，直接丢弃该块即可。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>                      |
 ┌────────────┐  ┌────┼─────┐  ┌───────────┐  ┌───────────┐  
 │ 1          │  │ 2  |     │  │ 3         │  │ 4         │ . . .
 └────────────┘  └────┼─────┘  └───────────┘  └───────────┘  
                      |
                      |
             retention boundary
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>用户可以通过命令行启动参数的方式修改本地存储的配置。</p><table><thead><tr><th>启动参数</th><th>默认值</th><th>含义</th></tr></thead><tbody><tr><td>--storage.tsdb.path</td><td>data/</td><td>Base path for metrics storage</td></tr><tr><td>--storage.tsdb.retention</td><td>15d</td><td>How long to retain samples in the storage</td></tr><tr><td>--storage.tsdb.min-block-duration</td><td>2h</td><td>The timestamp range of head blocks after which they get persisted</td></tr><tr><td>--storage.tsdb.max-block-duration</td><td>36h</td><td>The maximum timestamp range of compacted blocks,It&#39;s the minimum duration of any persisted block.</td></tr><tr><td>--storage.tsdb.no-lockfile</td><td>false</td><td>Do not create lockfile in data directory</td></tr></tbody></table><p>在一般情况下，Prometheus中存储的每一个样本大概占用1-2字节大小。</p><p>如果本地存储由于某些原因出现了错误，最直接的方式就是停止Prometheus并且删除data目录中的所有记录。当然也可以尝试删除那些发生错误的块目录，不过相应的用户会丢失该块中保存的大概两个小时的监控记录。</p><h2 id="远程存储" tabindex="-1"><a class="header-anchor" href="#远程存储" aria-hidden="true">#</a> 远程存储</h2><p>Prometheus的本地存储设计可以减少其自身运维和管理的复杂度，同时能够满足大部分用户监控规模的需求。但是本地存储也意味着Prometheus无法持久化数据，无法存储大量历史数据，同时也无法灵活扩展和迁移。</p><p>为了保持Prometheus的简单性，Prometheus并没有尝试在自身中解决以上问题，而是通过<strong>定义两个标准接口(remote_write/remote_read)</strong>，让用户可以基于这两个接口对接将数据<strong>保存到任意第三方的存储服务</strong>中，这种方式在Promthues中称为Remote Storage。</p><h3 id="remote-write" tabindex="-1"><a class="header-anchor" href="#remote-write" aria-hidden="true">#</a> Remote Write</h3><p>用户可以在Prometheus配置文件中指定Remote Write(远程写)的URL地址，一旦设置了该配置项，<strong>Prometheus将采集到的样本数据通过HTTP的形式发送给适配器(Adaptor)</strong>。而用户则可以在适配器中对接外部任意的服务。外部服务可以是真正的存储系统，公有云的存储服务，也可以是消息队列等任意形式。</p><img src="`+t+'" alt="screenshot2024-08-10 13.54.55" style="zoom:67%;"><h3 id="remote-read" tabindex="-1"><a class="header-anchor" href="#remote-read" aria-hidden="true">#</a> Remote Read</h3><p>如下图所示，Promthues的Remote Read(远程读)也通过了一个适配器实现。在远程读的流程当中，当用户发起查询请求后，Promthues将向remote_read中配置的URL发起查询请求(matchers,ranges)，Adaptor根据请求条件从第三方存储服务中获取响应的数据。同时将数据转换为Promthues的原始样本数据返回给Prometheus Server。</p><p>当获取到样本数据后，Promthues在本地使用PromQL对样本数据进行二次处理。</p><blockquote><p>注意：启用远程读设置后，只在数据查询时有效，对于规则文件的处理，以及Metadata API的处理都只基于Prometheus本地存储完成。</p></blockquote><img src="'+r+`" alt="screenshot2024-08-10 13.55.58" style="zoom:67%;"><h3 id="配置文件" tabindex="-1"><a class="header-anchor" href="#配置文件" aria-hidden="true">#</a> 配置文件</h3><p>Prometheus配置文件中添加remote_write和remote_read配置，其中url用于指定远程读/写的HTTP服务地址。如果该URL启动了认证则可以通过basic_auth进行安全认证配置。对于https的支持需要设定tls_concig。proxy_url主要用于Prometheus无法直接访问适配器服务的情况下。</p><p>remote_write和remote_write具体配置如下所示：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">remote_write</span><span class="token punctuation">:</span>
    <span class="token key atrule">url</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span>
    <span class="token punctuation">[</span> <span class="token key atrule">remote_timeout</span><span class="token punctuation">:</span> &lt;duration<span class="token punctuation">&gt;</span> <span class="token punctuation">|</span> default = 30s <span class="token punctuation">]</span>
    <span class="token key atrule">write_relabel_configs</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span> <span class="token punctuation">-</span> &lt;relabel_config<span class="token punctuation">&gt;</span> <span class="token punctuation">...</span> <span class="token punctuation">]</span>
    <span class="token key atrule">basic_auth</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span> <span class="token key atrule">username</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">password</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">bearer_token</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">bearer_token_file</span><span class="token punctuation">:</span> /path/to/bearer/token/file <span class="token punctuation">]</span>
    <span class="token key atrule">tls_config</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span> &lt;tls_config<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">proxy_url</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>

<span class="token key atrule">remote_read</span><span class="token punctuation">:</span>
    <span class="token key atrule">url</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span>
    <span class="token key atrule">required_matchers</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span> <span class="token key atrule">&lt;labelname&gt;</span><span class="token punctuation">:</span> &lt;labelvalue<span class="token punctuation">&gt;</span> <span class="token punctuation">...</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">remote_timeout</span><span class="token punctuation">:</span> &lt;duration<span class="token punctuation">&gt;</span> <span class="token punctuation">|</span> default = 30s <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">read_recent</span><span class="token punctuation">:</span> &lt;boolean<span class="token punctuation">&gt;</span> <span class="token punctuation">|</span> default = false <span class="token punctuation">]</span>
    <span class="token key atrule">basic_auth</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span> <span class="token key atrule">username</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">password</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">bearer_token</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">bearer_token_file</span><span class="token punctuation">:</span> /path/to/bearer/token/file <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> &lt;tls_config<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
    <span class="token punctuation">[</span> <span class="token key atrule">proxy_url</span><span class="token punctuation">:</span> &lt;string<span class="token punctuation">&gt;</span> <span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>当然，prometheus 提供了规定，可以让用户自定义 adapter，自己进行处理，这里不写了。</p><h2 id="联邦集群" tabindex="-1"><a class="header-anchor" href="#联邦集群" aria-hidden="true">#</a> 联邦集群</h2><p>通过Remote Storage可以分离监控样本采集和数据存储，解决Prometheus的持久化问题。联邦集群特性可以对Promthues进行扩展，以适应不同监控规模的变化。</p><p>对于大部分监控规模而言，只需要在每一个数据中心(例如：EC2可用区，Kubernetes集群)安装一个Prometheus Server实例，就可以在各个数据中心处理上千规模的集群。同时将Prometheus Server部署到不同的数据中心可以避免网络配置的复杂性。</p><img src="`+o+`" alt="screenshot2024-08-10 14.09.09" style="zoom:50%;"><p><strong>如上图所示，在每个数据中心部署单独的Prometheus Server，用于采集当前数据中心监控数据。并由一个中心的Prometheus Server负责聚合多个数据中心的监控数据。这一特性在Promthues中称为联邦集群。</strong></p><p>联邦集群的核心在于每一个Prometheus Server都包含一个用于获取当前实例中监控样本的接口/federate。对于中心Prometheus Server而言，无论是从其他的Prometheus实例还是Exporter实例中获取数据实际上并没有任何差异。</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">scrape_configs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">&#39;federate&#39;</span>
    <span class="token key atrule">scrape_interval</span><span class="token punctuation">:</span> 15s
    <span class="token key atrule">honor_labels</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
    <span class="token key atrule">metrics_path</span><span class="token punctuation">:</span> <span class="token string">&#39;/federate&#39;</span>
    <span class="token key atrule">params</span><span class="token punctuation">:</span>
      <span class="token key atrule">&#39;match[]&#39;</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token string">&#39;{job=&quot;prometheus&quot;}&#39;</span>
        <span class="token punctuation">-</span> <span class="token string">&#39;{__name__=~&quot;job:.*&quot;}&#39;</span>
        <span class="token punctuation">-</span> <span class="token string">&#39;{__name__=~&quot;node.*&quot;}&#39;</span>
    <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token string">&#39;192.168.77.11:9090&#39;</span>
        <span class="token punctuation">-</span> <span class="token string">&#39;192.168.77.12:9090&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为了有效的减少不必要的时间序列，通过params参数可以用于指定只获取某些时间序列的样本数据，例如</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>&quot;http://192.168.77.11:9090/federate?match[]={job%3D&quot;prometheus&quot;}&amp;match[]={__name__%3D~&quot;job%3A.*&quot;}&amp;match[]={__name__%3D~&quot;node.*&quot;}&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>通过URL中的match[]参数指定可以指定需要获取的时间序列。match[]参数必须是一个瞬时向量选择器，例如up或者{job=&quot;api-server&quot;}。配置多个match[]参数，用于获取多组时间序列的监控数据。</p><p><strong>horbor_labels</strong>配置true可以确保当采集到的监控指标冲突时，能够自动忽略冲突的监控数据。如果为false时，prometheus会自动将冲突的标签替换为”exported_“的形式。</p><blockquote><p>功能分区</p></blockquote><p>联邦集群的特性可以帮助用户根据不同的监控规模对Promthues部署架构进行调整。例如如下所示，可以在各个数据中心中部署多个Prometheus Server实例。每一个Prometheus Server实例只负责采集当前数据中心中的一部分任务(Job)，例如可以将不同的监控任务分离到不同的Prometheus实例当中，再有中心Prometheus实例进行聚合。哎，无非就是再多分一层罢了</p><img src="`+p+'" alt="screenshot2024-08-10 14.13.17" style="zoom:50%;"><p>功能分区，即通过联邦集群的特性在任务级别对Prometheus采集任务进行划分，以支持规模的扩展。</p><h2 id="prometheus高可用部署" tabindex="-1"><a class="header-anchor" href="#prometheus高可用部署" aria-hidden="true">#</a> Prometheus高可用部署</h2><p>Prometheus的本地存储给Prometheus带来了简单高效的使用体验，可以让Promthues在单节点的情况下满足大部分用户的监控需求。但是本地存储也同时限制了Prometheus的可扩展性，带来了数据持久化等一系列的问题。通过Prometheus的Remote Storage特性可以解决这一系列问题，包括Promthues的动态扩展，以及历史数据的存储。</p><p>而除了数据持久化问题以外，影响Promthues性能表现的另外一个重要因素就是数据采集任务量，以及单台Promthues能够处理的时间序列数。因此当监控规模大到Promthues单台无法有效处理的情况下，可以选择利用Promthues的联邦集群的特性，将Promthues的监控任务划分到不同的实例当中。</p><p>下面讨论Prometheus的高可用架构，并且根据不同的使用场景介绍了一种常见的高可用方案。</p><h3 id="基本ha-服务可用性" tabindex="-1"><a class="header-anchor" href="#基本ha-服务可用性" aria-hidden="true">#</a> 基本HA：服务可用性</h3><p>由于Promthues的Pull机制的设计，为了确保Promthues服务的可用性，用户只需要部署多套Prometheus Server实例，并且采集相同的Exporter目标即可。</p><img src="'+i+'" alt="screenshot2024-08-10 14.15.36" style="zoom:50%;"><p>基本的HA模式只能确保Promthues服务的可用性问题，但是不解决Prometheus Server之间的数据一致性问题以及持久化问题(数据丢失后无法恢复)，也无法进行动态的扩展。因此这种部署方式适合监控规模不大，Promthues Server也不会频繁发生迁移的情况，并且只需要保存短周期监控数据的场景。</p><h3 id="基本ha-远程存储" tabindex="-1"><a class="header-anchor" href="#基本ha-远程存储" aria-hidden="true">#</a> 基本HA + 远程存储</h3><p>在基本HA模式的基础上通过添加Remote Storage存储支持，将监控数据保存在第三方存储服务上</p><img src="'+l+'" alt="screenshot2024-08-10 14.16.16" style="zoom:50%;"><p>在解决了Promthues服务可用性的基础上，同时确保了数据的持久化，当Promthues Server发生宕机或者数据丢失的情况下，可以快速的恢复。 同时Promthues Server可能很好的进行迁移。因此，该方案适用于用户监控规模不大，但是希望能够将监控数据持久化，同时能够确保Promthues Server的可迁移性的场景。</p><h3 id="基本ha-远程存储-联邦集群" tabindex="-1"><a class="header-anchor" href="#基本ha-远程存储-联邦集群" aria-hidden="true">#</a> 基本HA + 远程存储 + 联邦集群</h3><p>当单台Promthues Server无法处理大量的采集任务时，用户可以考虑基于Prometheus联邦集群的方式将监控采集任务划分到不同的Promthues实例当中即在任务级别功能分区。</p><img src="'+u+'" alt="screenshot2024-08-10 14.18.37" style="zoom:50%;"><p>这种部署方式一般适用于两种场景：</p><p>场景一：单数据中心 + 大量的采集任务</p><p>这种场景下Promthues的性能瓶颈主要在于大量的采集任务，因此用户需要利用Prometheus联邦集群的特性，将不同类型的采集任务划分到不同的Promthues子服务中，从而实现功能分区。例如一个Promthues Server负责采集基础设施相关的监控指标，另外一个Prometheus Server负责采集应用监控指标。再有上层Prometheus Server实现对数据的汇聚。</p><p>场景二：多数据中心</p><p>这种模式也适合与多数据中心的情况，当Promthues Server无法直接与数据中心中的Exporter进行通讯时，在每一个数据中部署一个单独的Promthues Server负责当前数据中心的采集任务是一个不错的方式。这样可以避免用户进行大量的网络配置，只需要确保主Promthues Server实例能够与当前数据中心的Prometheus Server通讯即可。 中心Promthues Server负责实现对多数据中心数据的聚合。</p><h2 id="alertmanager高可用" tabindex="-1"><a class="header-anchor" href="#alertmanager高可用" aria-hidden="true">#</a> Alertmanager高可用</h2><p>为了提升Promthues的服务可用性，通常用户会部署两个或者两个以上的Promthus Server，它们具有完全相同的配置包括Job配置，以及告警配置等。当某一个Prometheus Server发生故障后可以确保Promthues持续可用。</p><img src="'+c+'" alt="screenshot2024-08-10 14.23.43" style="zoom:50%;"><p>同时基于Alertmanager的告警分组机制即使不同的Prometheus Sever分别发送相同的告警给Alertmanager，Alertmanager也可以自动将这些告警合并为一个通知向receiver发送。</p><img src="'+d+'" alt="screenshot2024-08-10 14.25.15" style="zoom:50%;"><p>但不幸的是，虽然Alertmanager能够同时处理多个相同的Prometheus Server所产生的告警。但是由于单个Alertmanager的存在，当前的部署结构存在明显的单点故障风险，当Alertmanager单点失效后，告警的后续所有业务全部失效。</p><p>如下所示，最直接的方式，就是尝试部署多套Alertmanager。但是由于Alertmanager之间不存在并不了解彼此的存在，因此则会出现告警通知被不同的Alertmanager重复发送多次的问题。</p><img src="'+m+'" alt="screenshot2024-08-10 14.25.45" style="zoom:50%;"><p>为了解决这一问题，如下所示。Alertmanager引入了Gossip机制。Gossip机制为多个Alertmanager之间提供了信息传递的机制。确保及时在多个Alertmanager分别接收到相同告警信息的情况下，也只有一个告警通知被发送给Receiver。</p><img src="'+h+'" alt="screenshot2024-08-10 14.26.18" style="zoom:50%;"><h3 id="gossip协议" tabindex="-1"><a class="header-anchor" href="#gossip协议" aria-hidden="true">#</a> Gossip协议</h3><p><strong>Gossip是分布式系统中被广泛使用的协议，用于实现分布式节点之间的信息交换和状态同步</strong>。Gossip协议同步状态类似于流言或者病毒的传播，如下所示：</p><img src="'+v+'" alt="screenshot2024-08-10 14.28.48" style="zoom:33%;"><p>一般来说Gossip有两种实现方式分别为Push-based和Pull-based。在Push-based当集群中某一节点A完成一个工作后，随机的从其它节点B并向其发送相应的消息，节点B接收到消息后在重复完成相同的工作，直到传播到集群中的所有节点。而Pull-based的实现中节点A会随机的向节点B发起询问是否有新的状态需要同步，如果有则返回。</p><p>如下所示，基于Gossip协议实现集群高可用，当Alertmanager接收到来自Prometheus的告警消息后，会按照以下流程对告警进行处理：</p><img src="'+k+'" alt="screenshot2024-08-10 14.30.17" style="zoom:50%;"><ol><li>在第一个阶段Silence中，Alertmanager会判断当前通知是否匹配到任何的静默规则，如果没有则进入下一个阶段，否则则中断流水线不发送通知。</li><li>在第二个阶段Wait中，Alertmanager会根据当前Alertmanager在集群中所在的顺序(index)等待index * 5s的时间。</li><li>当前Alertmanager等待阶段结束后，Dedup阶段则会判断当前Alertmanager数据库中该通知是否已经发送，如果已经发送则中断流水线，不发送告警，否则则进入下一阶段Send对外发送告警通知。</li><li>告警发送完成后该Alertmanager进入最后一个阶段Gossip，Gossip会通知其他Alertmanager实例当前告警已经发送。其他实例接收到Gossip消息后，则会在自己的数据库中保存该通知已发送的记录。</li></ol><p>因此如下所示，Gossip机制的关键在于两点：</p><img src="'+g+`" alt="screenshot2024-08-10 14.32.34" style="zoom:50%;"><ul><li>Silence设置同步：Alertmanager启动阶段<strong>基于Pull-based从集群其它节点同步Silence状态</strong>，当有新的Silence产生时使用Push-based方式在集群中传播Gossip信息。</li><li>通知发送状态同步：<strong>告警通知发送完成后，基于Push-based同步告警发送状态</strong>。Wait阶段可以确保集群状态一致。</li></ul><p>Alertmanager基于Gossip实现的集群机制虽然不能保证所有实例上的数据时刻保持一致，但是实现了CAP理论中的AP系统，即可用性和分区容错性。同时对于Prometheus Server而言保持了配置了简单性，Promthues Server之间不需要任何的状态同步。</p><h3 id="prometheus配置alertmanager集群" tabindex="-1"><a class="header-anchor" href="#prometheus配置alertmanager集群" aria-hidden="true">#</a> Prometheus配置Alertmanager集群</h3><p>由于Gossip机制的实现，在Promthues和Alertmanager实例之间不要使用任何的负载均衡，需要确保Promthues将告警发送到所有的Alertmanager实例中：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">alerting</span><span class="token punctuation">:</span>
  <span class="token key atrule">alertmanagers</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> 127.0.0.1<span class="token punctuation">:</span><span class="token number">9093</span>
      <span class="token punctuation">-</span> 127.0.0.1<span class="token punctuation">:</span><span class="token number">9094</span>
      <span class="token punctuation">-</span> 127.0.0.1<span class="token punctuation">:</span><span class="token number">9095</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,94),_=[P];function y(f,x){return e(),n("div",null,_)}const S=s(b,[["render",y],["__file","clustering.html.vue"]]);export{S as default};
